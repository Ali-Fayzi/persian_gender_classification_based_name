# -*- coding: utf-8 -*-
"""persian_name_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ysGFu3AJzkmiEhr8317OUY5aPbDYyolu

# Import Libraries
"""

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments , Trainer
from sklearn.model_selection import train_test_split

"""# Split Data to Train & Validation"""

import pandas as pd
import numpy as np
from sklearn.utils import shuffle
data_frame = pd.read_csv("/content/iranianNamesDataset.csv")
data_frame = shuffle(data_frame)
train_ = []
val_   = []
for row in data_frame.iterrows():
  if row[1]["Gender"] == "M":
      label = 0
  else:
      label = 1
  if np.random.rand () > 0.9:

    val_.append([row[1]["Names"],label])
  else:
    train_.append([row[1]["Names"],label])

"""# Save To CSV"""

train_frame = pd.DataFrame(train_,columns=["text","label"])
val_frame = pd.DataFrame(val_,columns=["text","label"])

train_frame.to_csv("train_names.csv",index=False)
val_frame.to_csv("val_names.csv",index=False)

"""# Load Dataset with datasets library"""

from datasets import load_dataset
geneder_classification = load_dataset("csv",data_files={
    "train":"/content/train_names.csv",
    "validation":"/content/val_names.csv"
})

geneder_classification

print(geneder_classification["train"][0])
print(geneder_classification["train"][-1])
print(geneder_classification["validation"][0])
print(geneder_classification["validation"][-1])

"""# Load Tokenizer and Model"""

model_id = "distilbert-base-uncased"

tokenizer = AutoTokenizer.from_pretrained(model_id)

def tokenize(batch):
  return tokenizer(batch["text"],padding=True,truncation=True)
names_encoded = geneder_classification.map(tokenize,batched=True,batch_size=None)

print(names_encoded["train"][0])
print(names_encoded["validation"][0])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("selected device : " , device)

num_labels = 2
model = AutoModelForSequenceClassification.from_pretrained(model_id,num_labels=num_labels).to(device)

"""# Train Arguments & Train Model"""

batch_size = 512
training_args = TrainingArguments(
    output_dir = "./output",
    num_train_epochs = 30,
    learning_rate = 0.00001,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=0.01,
    eval_strategy ="epoch",
    disable_tqdm=False,
    push_to_hub=False,
    report_to ="tensorboard",
)

from sklearn.metrics import accuracy_score,f1_score
def compute_metrics(pred):
  labels = pred.label_ids
  preds  = pred.predictions.argmax(-1)
  f1 = f1_score(labels, preds, average='weighted')
  acc = accuracy_score(labels, preds)
  return {"accuracy": acc,"f1": f1}
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset = names_encoded["train"],
    eval_dataset  = names_encoded["validation"],
    compute_metrics = compute_metrics,
    tokenizer=tokenizer,
)

trainer.train()

idx_to_name = {
    0:"Male",
    1:"Women"
}
name ="کبری"
encoded_name = tokenizer(name,return_tensors="pt").to(device)
output = model(encoded_name["input_ids"])
print(idx_to_name[output.logits.argmax(-1).item()])

